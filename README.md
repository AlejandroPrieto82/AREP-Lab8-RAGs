# Introducci√≥n a la Creaci√≥n de RAGs (Retrieval-Augmented Generators) con OpenAI

## üìñ Enunciado del Laboratorio
Este laboratorio introduce a los estudiantes en los conceptos fundamentales y la implementaci√≥n pr√°ctica de **Retrieval-Augmented Generators (RAGs)** utilizando las herramientas de **OpenAI** y el framework **LangChain**.  
Al finalizar, los estudiantes habr√°n adquirido experiencia pr√°ctica construyendo y entendiendo RAGs, culminando en la entrega de **dos repositorios en GitHub** que muestran su trabajo.

- **Repositorio 1**: Implementaci√≥n b√°sica del tutorial de LangChain LLM Chain.  
- **Repositorio 2**: Proyecto RAG utilizando Pinecone como base de datos vectorial y OpenAI para embeddings y LLM.

---

## üéØ Objetivos
- Comprender el concepto de **Retrieval-Augmented Generation (RAG)**.  
- Aprender c√≥mo LangChain integra mecanismos de recuperaci√≥n con modelos generativos.  
- Construir un pipeline RAG con Pinecone y OpenAI.  
- Entregar dos repositorios en GitHub con c√≥digo y documentaci√≥n.

---

## üõ†Ô∏è Preparaci√≥n Previa
Antes de comenzar, revisa los siguientes tutoriales oficiales de LangChain:
- [Tutorial LLM Chain](https://python.langchain.com/docs/tutorials/llm_chain/)  
- [Tutorial RAG](https://python.langchain.com/docs/tutorials/rag/)  

Estos recursos proporcionan la base necesaria para construir aplicaciones avanzadas con LangChain.

---

## üìÇ Arquitectura del Proyecto

### Repositorio 1: LLM Chain B√°sico
- **Componentes**:
  - Modelo `ChatOpenAI` desde `langchain_openai`.
  - Plantillas de prompt simples.
  - Ejecuci√≥n de cadenas con consultas de usuario.
- **Objetivo**: Demostrar c√≥mo conectar un LLM con un prompt y ejecutar consultas.

### Repositorio 2: Proyecto RAG
- **Componentes**:
  - **Document Loader**: Carga de archivos de texto o PDF.  
  - **Text Splitter**: Divisi√≥n de documentos en fragmentos para embeddings.  
  - **Embeddings**: Uso de embeddings de OpenAI (`text-embedding-3-small` o similar).  
  - **Vector Store**: Pinecone como base de datos vectorial.  
  - **Retriever**: Consulta a Pinecone para obtener fragmentos relevantes.  
  - **Agente/Chain**: Combina el contexto recuperado con el LLM para responder preguntas.

---

## ‚öôÔ∏è Instalaci√≥n

Clona el repositorio y instala las dependencias:

```bash
git clone <repo-url>
cd <repo-folder>
pip install -U langchain langchain-community langchain-openai pinecone
```

Configura tus claves de API como variables de entorno:

```bash
export OPENAI_API_KEY="tu_api_key_de_openai"
export PINECONE_API_KEY="tu_api_key_de_pinecone"
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n del C√≥digo

### Repositorio 1 (LLM Chain)
```bash
python llm_chain_demo.py
```

### Repositorio 2 (RAG Project)
```bash
python rag_pipeline.py
```

---

## üì∏ Ejemplo de Salida

- **LLM Chain**:  
  Entrada: `"Explica qu√© es la descomposici√≥n de tareas"`  
  Salida: `"La descomposici√≥n de tareas es el proceso de dividir tareas complejas en subtareas manejables..."`

- **RAG Project**:  
  Entrada: `"¬øCu√°l es el m√©todo est√°ndar para la descomposici√≥n de tareas?"`  
  Salida:  
  El modelo recupera contexto relevante desde Pinecone y genera una respuesta enriquecida.

---

## üìù Requisitos del README
- Arquitectura y componentes explicados.  
- Instrucciones paso a paso de instalaci√≥n y ejecuci√≥n.  
- Ejemplos de salida incluidos.  

---

## ‚ö†Ô∏è Nota Importante
Durante el taller enfrentamos **problemas de compatibilidad con librer√≠as y el entorno en Jupyter**:
- Diferencias entre versiones de `pinecone-client` y `pinecone` que generaban errores de conexi√≥n.  
- Algunos imports de LangChain (`create_openai_functions_agent`) fueron deprecados en versiones recientes.  
- Inconsistencias del kernel de Jupyter dificultaron mantener un entorno estable.  

üëâ Por estas razones, **no pudimos ejecutar el pipeline RAG de forma completa dentro de Jupyter**, aunque el c√≥digo y la documentaci√≥n siguen las mejores pr√°cticas y los tutoriales oficiales. Los repositorios sirven como referencia y artefacto de aprendizaje.

---

## ‚úÖ Criterios de Evaluaci√≥n
- C√≥digo completo y alineado con los tutoriales.  
- Documentaci√≥n clara y detallada en el README.  
- Organizaci√≥n adecuada de los repositorios en GitHub.  

